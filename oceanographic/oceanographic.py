# -*- coding: utf-8 -*-
"""
NOAA Tide Data Downloader & Daily Aggregator
- ä¸‹è½½é€å°æ—¶æ½®ä½ (hourly_height)
- ä¿å­˜åˆ°æ¡Œé¢ ~/Desktop/noaa_raw/
- åˆå¹¶å¹´åº¦æ–‡ä»¶ & ç”Ÿæˆé€æ—¥æœ€å¤§æ½®ä½åˆ° ~/Desktop/noaa_daily/
"""

import os
import time
from pathlib import Path
from typing import List, Dict
import requests
import pandas as pd

BASE_URL = "https://api.tidesandcurrents.noaa.gov/api/prod/datagetter"

# ====== ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é…ç½® ======
YEARS = list(range(2015, 2025))  # 2015-2024
STATIONS: Dict[str, str] = {
    "8723214": "Miami (Virginia Key)",      # Florida
    "8761927": "New Orleans (New Canal)",   # Louisiana
    "8638610": "Norfolk (Sewells Point)",   # Virginia
}
# ==================================

def desktop_path() -> Path:
    # è·¨å¹³å°è·å–æ¡Œé¢è·¯å¾„ï¼ˆé»˜è®¤ ~/Desktopï¼‰
    d = Path.home() / "Desktop"
    d.mkdir(exist_ok=True)
    return d

def ensure_dir(p: Path) -> Path:
    p.mkdir(parents=True, exist_ok=True)
    return p

def fetch_one_year(station_id: str, year: int, out_dir: Path, retries: int = 3, sleep_base: int = 2) -> Path:
    """ä¸‹è½½æŸç«™ç‚¹æŸä¸€å¹´çš„é€å°æ—¶æ½®ä½CSVï¼Œè¿”å›ä¿å­˜è·¯å¾„ã€‚"""
    params = {
        "begin_date": f"{year}0101",
        "end_date":   f"{year}1231",
        "station": station_id,
        "product": "hourly_height",
        "datum": "MSL",
        "units": "metric",
        "time_zone": "gmt",
        "format": "csv",
    }
    fn = out_dir / f"{station_id}_{year}_hourly.csv"
    if fn.exists() and fn.stat().st_size > 200:  # å·²å­˜åœ¨ä¸”éç©º
        print(f"â© skip existing {fn.name}")
        return fn

    for attempt in range(1, retries + 1):
        try:
            r = requests.get(BASE_URL, params=params, timeout=60)
            r.raise_for_status()
            txt_head = r.text[:200].lower()
            if "<html" in txt_head or "error" in txt_head:
                raise RuntimeError(txt_head[:120])
            fn.write_bytes(r.content)
            print(f"âœ… downloaded {fn.name}")
            return fn
        except Exception as e:
            print(f"âš ï¸ retry {attempt}/{retries} {station_id}-{year}: {e}")
            time.sleep(sleep_base * attempt)
    raise RuntimeError(f"âŒ failed {station_id}-{year}")

def merge_years(station_id: str, year_files: List[Path], out_dir: Path) -> Path:
    """åˆå¹¶å¹´åº¦CSVä¸ºä¸€ä¸ªå¤§CSVã€‚"""
    dfs = []
    for p in year_files:
        df = pd.read_csv(p)
        dfs.append(df)
    merged = pd.concat(dfs, ignore_index=True)
    merged_fn = out_dir / f"{station_id}_{YEARS[0]}_{YEARS[-1]}_hourly_merged.csv"
    merged.to_csv(merged_fn, index=False)
    print(f"ğŸ“¦ merged -> {merged_fn.name}")
    return merged_fn

def hourly_to_daily_max(in_csv: Path, city_label: str, out_dir: Path) -> Path:
    """ä»é€å°æ—¶CSVç”Ÿæˆé€æ—¥æœ€å¤§æ½®ä½CSVã€‚"""
    df = pd.read_csv(in_csv)
    # æ ‡å‡†åŒ–åˆ—å
    df.columns = [c.strip().lower().replace("  ", " ") for c in df.columns]

    # è¯†åˆ«æ—¶é—´åˆ— & æ°´ä½åˆ—ï¼ˆä¸åŒç«™ç‚¹çš„åˆ—åå¯èƒ½ç•¥æœ‰ä¸åŒï¼‰
    time_col = next((c for c in ["date time", "date_time", "datetime", "time"] if c in df.columns), None)
    level_col = next((c for c in ["water level", "water_level", "waterlevel", "observed", "value"] if c in df.columns), None)
    if time_col is None or level_col is None:
        raise ValueError(f"åˆ—åæ— æ³•è¯†åˆ«ï¼Œçœ‹çœ‹è¿™äº›åˆ—ï¼š{df.columns.tolist()}")

    # è´¨é‡æ§åˆ¶ï¼ˆå¦‚æœ‰â€œquality/qc/flagâ€ï¼Œä¿ç•™ 'v' æˆ–ç©ºï¼‰
    for qc in ["quality", "qc", "flag"]:
        if qc in df.columns:
            df = df[df[qc].astype(str).str.lower().isin(["v", "nan", ""])]

    # è½¬æ—¶é—´ä¸èšåˆ
    df["datetime"] = pd.to_datetime(df[time_col], utc=True, errors="coerce")
    df = df.dropna(subset=["datetime"])
    df["date"] = df["datetime"].dt.date
    daily = (df.groupby("date")[level_col]
               .max()
               .reset_index()
               .rename(columns={level_col: "daily_max_tide_m"}))
    daily["city"] = city_label

    out_fn = out_dir / f"{in_csv.stem.replace('_hourly_merged','').replace('_hourly','')}_daily_max.csv"
    daily.to_csv(out_fn, index=False)
    print(f"ğŸ—“ï¸ daily -> {out_fn.name} ({len(daily)} rows)")
    return out_fn

def main():
    desk = desktop_path()
    raw_dir = ensure_dir(desk / "noaa_raw")
    daily_dir = ensure_dir(desk / "noaa_daily")

    for station_id, city_label in STATIONS.items():
        print(f"\n=== {city_label} ({station_id}) ===")
        # é€å¹´ä¸‹è½½
        files = [fetch_one_year(station_id, y, raw_dir) for y in YEARS]
        # åˆå¹¶
        merged = merge_years(station_id, files, raw_dir)
        # è½¬é€æ—¥
        hourly_to_daily_max(merged, city_label, daily_dir)

    print("\nâœ… All done.")
    print(f"Raw files dir:    {raw_dir}")
    print(f"Daily files dir:  {daily_dir}")

if __name__ == "__main__":
    main()
